.. |br| raw:: html

  <br/>
  
References
==========

**Summary:** This a is non-exhaustive list of references for this component.

|

.. contents:: **Table of Contents**

|

Most of the methods below use *Self-Supervised Learning* for the stage of *Preprocessing*.


Using model-based Reinforcement Learning
----------------------------------------

**2018**

- `Recall Traces: Backtracking Models for Efficient Reinforcement Learning <https://arxiv.org/pdf/1804.00379.pdf>`_

**2019**

- `Task-Agnostic Dynamics Priors for Deep Reinforcement Learning <https://arxiv.org/pdf/1905.04819.pdf>`_

Using Dynamical Systems
-----------------------

**2016**

- `Kernel Learning for Dynamic Texture Synthesis <https://www.researchgate.net/profile/Shujian-Yu/publication/308772804_Kernel_Learning_for_Dynamic_Texture_Synthesis/links/5aa94130458515178818a7c7/Kernel-Learning-for-Dynamic-Texture-Synthesis.pdf>`_

**2021**

- `Discovering State Variables Hidden in Experimental Data <https://arxiv.org/pdf/2112.10755.pdf>`_

**2022**

- `Automated discovery of fundamental variables hidden in experimental data <http://generalroboticslab.com/assets/files/NSV_paper.pdf>`_
